{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3fe7f1",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ed6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e743057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb1d282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4269629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f80555",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = os.getenv(\"RAW_DIR\")\n",
    "DATASET_DIR = os.getenv(\"DATASETS_DIR\")\n",
    "PROCESSED_DIR = os.getenv(\"PROCESSED_DIR\")\n",
    "\n",
    "WEATHER_DATASET = output_path = os.path.join(DATASET_DIR, \"weather_sj_2010_2017.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8557c772",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d40182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the raw data\n",
    "if not os.path.exists(RAW_DIR):\n",
    "    raise FileNotFoundError(f\"Directory {RAW_DIR} not found\")\n",
    "    \n",
    "if not os.path.exists(PROCESSED_DIR):\n",
    "    os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "csv_files = glob.glob(os.path.join(RAW_DIR, \"*.csv\"))\n",
    "\n",
    "dfs = [pd.read_csv(file) for file in csv_files]\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "merged_df['datetime'] = pd.to_datetime(merged_df['datetime'])  # Adjust column name if different\n",
    "merged_df = merged_df.sort_values('datetime')\n",
    "merged_df.to_csv(PROCESSED_FILE, index=False)\n",
    "\n",
    "print(f\"Successfully merged CSVs saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02980a94",
   "metadata": {},
   "source": [
    "### Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb043e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv(WEATHER_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef37cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.info(), weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NULL values values\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.heatmap(weather_df.isnull(), cbar=False, cmap=\"viridis\")\n",
    "plt.title(\"NULL Values Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicate rows\n",
    "duplicates = weather_df.duplicated().sum()\n",
    "print(f\"Number of duplicated rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6bb54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicated dates\n",
    "duplicate_dates = weather_df[\"datetime\"].duplicated().sum()\n",
    "print(f\"Number of duplicated dates: {duplicate_dates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e6da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for skipped dates\n",
    "start_date = weather_df[\"datetime\"].min()\n",
    "end_date = weather_df[\"datetime\"].max()\n",
    "\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "missing_dates = date_range[~date_range.isin(pd.to_datetime(weather_df[\"datetime\"]))]\n",
    "missing_dates_list = missing_dates.strftime(\"%Y-%m-%d\").tolist()\n",
    "\n",
    "print(f\"Missing dates: {len(missing_dates_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aabc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for features with outliers\n",
    "\n",
    "outlier_features = []\n",
    "for col in weather_df.select_dtypes(include=[\"number\"]).columns:\n",
    "    q1 = weather_df[col].quantile(0.25)\n",
    "    q3 = weather_df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    if ((weather_df[col] < lower_bound) | (weather_df[col] > upper_bound)).any():\n",
    "        outlier_features.append(col)\n",
    "\n",
    "print(f\"Features with outliers: {outlier_features}\")\n",
    "\n",
    "plt.figure(figsize=(len(outlier_features), 5))  # Adjust width depending on number of features\n",
    "\n",
    "plt.boxplot([weather_df[col].dropna() for col in outlier_features], tick_labels=outlier_features)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Features with Outliers')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
